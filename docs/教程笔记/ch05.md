# ⑤ 人工智能领域中常见词汇详解

## batch-size（训练选取样本数）

batch-size顾名思义就是批次大小，也就是一次训练选取的样本个数．batch-size的大小对模型的优化和速度都是很有影响的．尤其是你的GPU的个数不多时，最好不要把数值设置的很大．batchsize的正确选择是为了在内存效率和内存容量之间寻找最佳平衡。

## epoch（训练轮数）

epoch数是一个超参数，它定义了学习算法在整个训练数据集中的工作次数。一个Epoch意味着训练数据集中的每个样本都有机会更新内部模型参数。Epoch由一个或多个Batch组成, 具有一批的Epoch称为批量梯度下降学习算法。您可以将for循环放在每个需要遍历训练数据集的epoch上，在这个for循环中是另一个嵌套的for循环，它遍历每批样本，其中一个批次具有指定的“批量大小”样本数
