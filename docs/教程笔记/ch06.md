# ⑥ Transformer模型架构各层详解

注：本文仅介绍最原始的Transformer模型架构，不涉及任何改进方法。

## 一、什么是Transformer？

以下是Transformer模型的整体架构图：

![Alt text](20200324202147216.png)

Transformer 是一种深度学习模型架构，用于处理序列数据，特别是在自然语言处理（NLP）任务中取得了巨大成功。它于2017年由Vaswani等人在论文《Attention is All You Need》中首次提出。在这之前，循环神经网络（RNN）和长短时记忆网络（LSTM）等传统的循环结构在序列建模中非常流行，但在处理长序列时存在一些限制。最开始只有模型的含义，经过几年的发展，Transformer现如今已成为一个基本架构，并衍生出许多改进方法（简称：**魔改**）

## 二、Transformer的表层分析

在不深究微观内层，只从表面上看，和大多数seq2seq模型一样，transformer的结构也是由encoder（编码器）和decoder（解码器）两部分组成。下面，我们将分别且详细地介绍encoder（编码器）和decoder（解码器）这两部分内部的各层网络。

## 三、Transformer的内层分析

### 3.1 Encoder

#### ①
