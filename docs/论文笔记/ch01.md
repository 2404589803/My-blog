# ①  GAIA: a benchmark for General AI Assistants（GAIA：通用人工智能助手的基准）


## 一、 AI理解的重点：
1. GAIA 是一个用于评估通用助手类问题的基准，试图避免评估过程中存在的陷阱。
2. GAIA 由 466 个问题组成，由人类设计和标注。这些问题旨在涵盖各种助手使用场景，如日常个人任务、科学或一般知识。
3. 问题设计成只有一个简短正确答案，便于验证。
4. 使用 GAIA 只需要向 AI 助手提供问题和附加证据（如果有的话）。
5. 在 GAIA 上取得完美的成绩需要一系列基本能力（见第 3.3 节）。
6. GAIA 成绩既来自需要更新 AI 基准的必要性，也来自观察到 LLM 评估的不足。
7. 我们的第一个原则是目标问题在概念上简单，但潜在地为人类乏味，且丰富多样，立足于现实世界，挑战当前 AI 系统。这使我们能够专注于基本能力，如通过推理快速适应、多模态理解以及潜在的多种工具使用，而不是专门技能。
8. 这些问题通常涉及从不同来源获取信息并将其转换为准确答案的过程，例如提供的文档或不断变化的网络。
9. 回答第一个问题（图 1），例如 LLMs 通常需要浏览网络才能找到研究，然后寻找正确的注册。这与评估指标的趋势相反，评估指标变得越来越难以理解和操作，或者纯粹在文本或人工环境中运行。
10. 我们的第二个原则是可解释性。由于问题集有限，高度 curated，因此 GAIA 相对于聚合的指标来说更容易使用。任务的简单概念（人类成功率 92%）使得用户更容易理解模型的推理过程。
11. 从图 1 的第一级问题来看，推理痕迹的大部分内容将是检查正确网站，并报告正确的注册，这是容易验证的。
12. 我们第三个原则是抵制记忆的鲁棒性。为了完成任务，系统必须计划并成功完成某些步骤，因为结果答案在当前预训练数据中缺失。准确性的提高反映了系统实际进步。
13. 由于它们的多样性和动作空间的规模，这些任务不能被暴力破解，例如通过记住地面真理。尽管意外的内存是可能的，通过数据污染，答案的缺失和检查推理痕迹的可能性，这方面的风险得到减轻。
14. 相比之下，多选题答案使得污染评估困难，因为错误的推理痕迹仍然可以通往正确答案。如果尽管这些减轻措施出现了灾难性的内存，也可以使用我们提供的指南（见第 3.4 节）制作新问题。

## 二、个人论文精读